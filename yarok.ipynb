{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yarok.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNGXoNVceFK4KmpwNxhO+TK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eyaler/avatars4all/blob/master/yarok.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_ETOKoCh2ur"
      },
      "source": [
        "# Video Green Screen\r\n",
        "\r\n",
        "## Qin et al., U^2-Net: Going Deeper with Nested U-Structure for Salient Object Detection, https://arxiv.org/abs/2005.09007, https://github.com/NathanUA/U-2-Net\r\n",
        "\r\n",
        "## Ke et al., MODNet: Is a Green Screen Really Necessary for Real-Time Portrait Matting?, https://arxiv.org/abs/2011.11961, https://github.com/ZHKKKe/MODNet\r\n",
        "\r\n",
        "### Made just a little bit more accessible by Eyal Gruss (https://eyalgruss.com, eyalgruss@gmail.com)\r\n",
        "\r\n",
        "#### Foreground options:\r\n",
        "*   Image from web or upload\r\n",
        "*   Video from web or upload\r\n",
        "*   Trim video start time and duration\r\n",
        "*   Mirror versions of the above\r\n",
        "\r\n",
        "#### Model options:\r\n",
        "*   U^2-Net\r\n",
        "*   MODNet photographic model\r\n",
        "*   MODNet \"webcam\" model\r\n",
        "*   U^2-Net portrait generation (sketch)\r\n",
        "*   U^2-Net portrait generation + U^2-Net blending\r\n",
        "*   U^2-Net preprocessing + U^2-Net portrait generation\r\n",
        "*   U^2-Net preprocessing + U^2-Net portrait generation + U^2-Net blending\r\n",
        "\r\n",
        "#### Blending options:\r\n",
        "*   Continuous blending\r\n",
        "*   One frame delay smoothing with custom threshold\r\n",
        "*   Gra sketch colors from original foreground\r\n",
        "\r\n",
        "#### Background options:\r\n",
        "*   Solid white, black, chroma green, chroma blue or any hex value\r\n",
        "*   Transparent (for images)\r\n",
        "*   Image from web or upload\r\n",
        "*   Video from web or upload\r\n",
        "*   Trim video start time and duration\r\n",
        "*   Loop video from start or in reverse\r\n",
        "*   Resize to match foreground, optionally keeping aspect ratio\r\n",
        "*   Foreground image/video with optional following effects\r\n",
        "*   Bokeh (gamma-corrected blurred) versions of the above\r\n",
        "*   Grayscale versions of the above\r\n",
        "*   Mirror versions of the above\r\n",
        "\r\n",
        "##### List of more generative tools: https://j.mp/generativetools\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K5a29Wbgi0L",
        "cellView": "form"
      },
      "source": [
        "#@title Setup\r\n",
        "%cd /content\r\n",
        "!git clone --depth 1 https://github.com/NathanUA/U-2-Net\r\n",
        "!mkdir -p /content/U-2-Net/saved_models/u2net\r\n",
        "%cd /content/U-2-Net/saved_models/u2net\r\n",
        "!wget --no-check-certificate -nc https://eyalgruss.com/fomm/u2net.pth\r\n",
        "!wget --no-check-certificate -nc https://eyalgruss.com/fomm/u2netp.pth\r\n",
        "!mkdir -p /content/U-2-Net/saved_models/u2net_portrait\r\n",
        "%cd /content/U-2-Net/saved_models/u2net_portrait\r\n",
        "!wget --no-check-certificate -nc https://eyalgruss.com/fomm/u2net_portrait.pth\r\n",
        "%cd /content\r\n",
        "!git clone --depth 1 https://github.com/ZHKKKe/MODNet\r\n",
        "%cd MODNet/pretrained\r\n",
        "!wget --no-check-certificate -nc https://eyalgruss.com/fomm/modnet_photographic_portrait_matting.ckpt\r\n",
        "!wget --no-check-certificate -nc https://eyalgruss.com/fomm/modnet_webcam_portrait_matting.ckpt\r\n",
        "%cd /content\r\n",
        "!pip install -U youtube-dl\r\n",
        "!pip install -U imageio\r\n",
        "!pip install -U imageio-ffmpeg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGtTGhKUh1fW",
        "cellView": "form"
      },
      "source": [
        "#@title Get the foreground image/video and background image/video from the web\r\n",
        "#@markdown 1. You can change the URLs to your **own** stuff!\r\n",
        "#@markdown 2. For the background you can use the drop-down menu to alternatively choose a **solid color**, **transparent** (for images only) or the **foreground** iteslf (with optional effects). You can also feed a **hex** color value (e.g. de0000 or #de0000)\r\n",
        "#@markdown 3. Alternatively, you can upload **local** files in the next cells\r\n",
        "\r\n",
        "#foreground_url = 'https://www.youtube.com/watch?v=HzpzvAPj1kw' #@param {type:\"string\"}\r\n",
        "#background_url = 'https://www.youtube.com/watch?v=pXpvh6eIFBk' #@param ['White', 'Black', 'Chroma Green', 'Chroma Blue', 'Transparent', 'Foreground'] {allow-input: true}\r\n",
        "\r\n",
        "#foreground_url = 'https://www.youtube.com/watch?v=kMpnwIGDQvU' #@param {type:\"string\"}\r\n",
        "#background_url = 'https://www.youtube.com/watch?v=dMvnCyznteU' #@param ['White', 'Black', 'Chroma Green', 'Chroma Blue', 'Transparent', 'Foreground'] {allow-input: true}\r\n",
        "\r\n",
        "foreground_url = 'https://www.youtube.com/watch?v=kMpnwIGDQvU' #@param {type:\"string\"}\r\n",
        "background_url = 'https://www.youtube.com/watch?v=dMvnCyznteU' #@param ['White', 'Black', 'Chroma Green', 'Chroma Blue', 'Transparent', 'Foreground'] {allow-input: true}\r\n",
        "\r\n",
        "import os\r\n",
        "import youtube_dl\r\n",
        "def is_supported(url):\r\n",
        "    if url.lower().endswith(('.png','.jpg','.jpeg','.bmp')):\r\n",
        "      return False\r\n",
        "    extractors = youtube_dl.extractor.gen_extractors()\r\n",
        "    for e in extractors:\r\n",
        "        if e.suitable(url) and e.IE_NAME != 'generic':\r\n",
        "            return True\r\n",
        "    return False\r\n",
        "\r\n",
        "if foreground_url:\r\n",
        "  !rm -f /content/foreground\r\n",
        "  if is_supported(foreground_url):\r\n",
        "    !rm -f /content/foreground.mp4\r\n",
        "    !youtube-dl -f 'bestvideo[ext=mp4][vcodec!*=av01]+bestaudio[ext=m4a]/mp4' '$foreground_url' --merge-output-format mp4 -o /content/foreground\r\n",
        "    !mv /content/foreground.mp4 /content/foreground \r\n",
        "    fg_time_params = ''\r\n",
        "  if not os.path.exists('/content/foreground'):\r\n",
        "    !wget '$foreground_url' -O /content/foreground\r\n",
        "\r\n",
        "if '://' in background_url:\r\n",
        "  !rm -f /content/background\r\n",
        "  if is_supported(background_url):\r\n",
        "    !rm -f /content/background.mp4\r\n",
        "    !youtube-dl -f 'bestvideo[ext=mp4][vcodec!*=av01]+bestaudio[ext=m4a]/mp4' '$background_url' --merge-output-format mp4 -o /content/background\r\n",
        "    !mv /content/background.mp4 /content/background\r\n",
        "    bg_time_params = ''\r\n",
        "  if not os.path.exists('/content/background'):\r\n",
        "    !wget '$background_url' -O /content/background\r\n",
        "else:\r\n",
        "  background_url = background_url.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrx-hEY-ir8K",
        "cellView": "form"
      },
      "source": [
        "#@title Optionally upload foreground image/video { run: \"auto\" }\r\n",
        "manually_upload_foreground = False #@param {type:\"boolean\"}\r\n",
        "if manually_upload_foreground:\r\n",
        "  from google.colab import files\r\n",
        "  import shutil\r\n",
        "\r\n",
        "  %cd /content/sample_data\r\n",
        "  try:\r\n",
        "    uploaded = files.upload()\r\n",
        "  except Exception as e:\r\n",
        "    %cd /content\r\n",
        "    raise e\r\n",
        "\r\n",
        "  for fn in uploaded:\r\n",
        "    shutil.move('/content/sample_data/'+fn, '/content/foreground')\r\n",
        "    break\r\n",
        "  foreground_url = None\r\n",
        "  fg_time_params = ''\r\n",
        "  %cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4mryuGkitnR",
        "cellView": "form"
      },
      "source": [
        "#@title Optionally upload local background image/video { run: \"auto\" }\r\n",
        "manually_upload_background = False #@param {type:\"boolean\"}\r\n",
        "if manually_upload_background:\r\n",
        "  from google.colab import files\r\n",
        "  import shutil\r\n",
        "\r\n",
        "  %cd /content/sample_data\r\n",
        "  try:\r\n",
        "    uploaded = files.upload()\r\n",
        "  except Exception as e:\r\n",
        "    %cd /content\r\n",
        "    raise e\r\n",
        "\r\n",
        "  for fn in uploaded:\r\n",
        "    shutil.move('/content/sample_data/'+fn, '/content/background')\r\n",
        "    break\r\n",
        "  background_url = None\r\n",
        "  bg_time_params = ''\r\n",
        "  %cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D7krlDMixkC",
        "cellView": "form"
      },
      "source": [
        "#@title Optionally shorten foreground video\r\n",
        "start_seconds =  0#@param {type:\"number\"}\r\n",
        "duration_seconds =  60#@param {type:\"number\"}\r\n",
        "start_seconds = max(start_seconds,0)\r\n",
        "duration_seconds = max(duration_seconds,0)\r\n",
        "fg_time_params = ''\r\n",
        "if duration_seconds: \r\n",
        "  fg_time_params = '-ss %i -t %i'%(start_seconds, duration_seconds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHl_Xkeamau_",
        "cellView": "form"
      },
      "source": [
        "#@title Optionally shorten background video\r\n",
        "start_seconds =  0#@param {type:\"number\"}\r\n",
        "duration_seconds =  60#@param {type:\"number\"}\r\n",
        "start_seconds = max(start_seconds,0)\r\n",
        "duration_seconds = max(duration_seconds,0)\r\n",
        "bg_time_params = ''\r\n",
        "if duration_seconds:\r\n",
        "  bg_time_params = '-ss %i -t %i'%(start_seconds, duration_seconds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8otpdxD88FH",
        "cellView": "form"
      },
      "source": [
        "#@title Green screen it!\r\n",
        "#@markdown Model notes:\r\n",
        "#@markdown 1. u2net tends to remove more unwanted parts, but may also remove desired parts of the foreground objects.\r\n",
        "#@markdown 2. modnet tends to keep more of the desired parts and also gives a finer boundary, but may leave in more unwanted parts (which is the more useful option if you further post edit the video).\r\n",
        "#@markdown 3. u2net_portrait will generate a sketch + if background is image/video/\"Foreground\" then use u2net mask of the original foreground to blend with that background.\r\n",
        "#@markdown 4. u2net + u2net_portrait adds a preprocessing stage to remove the background before generating a sketch of the forground.\r\n",
        "#@markdown\r\n",
        "#@markdown Sketching notes:\r\n",
        "#@markdown 1. background=\"White\" + model=\"u2net_portrait\" -> everything becomes a sketch\r\n",
        "#@markdown 2. background=\"Foreground\" + model=\"u2net_portrait\" -> sketched foreground on top of original background\r\n",
        "#@markdown 3. background=\"White\" + model=\"u2net + u2net_portrait\" -> sketched foreground with white background\r\n",
        "#@markdown 4. background=\"Foreground\" + model=\"u2net + u2net_portrait\" -> variation similar to (2)\r\n",
        "#@markdown 5. background=upload result of (1) + model=\"u2net\" -> original foreground on top of sketched background  \r\n",
        "\r\n",
        "model = 'u2net' #@param ['u2net', 'modnet_photographic', 'modnet_webcam', 'u2net_portrait', 'u2net + u2net_portrait']\r\n",
        "sketch_color = 'Gray' #@param ['Gray','Foreground','Tint outline','Tint fill']\r\n",
        "one_frame_delay = True #@param {type:\"boolean\"} \r\n",
        "one_frame_delay_threshold = 0.1 #@param {type:\"slider\", min:0, max:1, step:0.05}\r\n",
        "mirror_foreground = False #@param {type:\"boolean\"} \r\n",
        "mirror_background = False #@param {type:\"boolean\"} \r\n",
        "gray_background = False #@param {type:\"boolean\"} \r\n",
        "bokeh_background = False #@param {type:\"boolean\"} \r\n",
        "bokeh_prcnt = 5 #@param {type:\"slider\", min:1, max:50, step:1}\r\n",
        "bokeh_gamma = 5 #@param {type:\"slider\", min:1, max:50, step:1}\r\n",
        "keep_aspect_background = True #@param {type:\"boolean\"}\r\n",
        "loop_reverse_background = False #@param {type:\"boolean\"}\r\n",
        "copy_audio = True #@param {type:\"boolean\"}\r\n",
        "bg_mode_max_w = 1920\r\n",
        "chroma_thresholds = [0.5,0.25]\r\n",
        "sketch_color = sketch_color.lower()\r\n",
        "\r\n",
        "%cd /content\r\n",
        "fg_dir = '/content/U-2-Net/test_data/test_images'\r\n",
        "mask_dir = '/content/U-2-Net/test_data/u2net_results'\r\n",
        "bg_dir = '/content/bg_frames'\r\n",
        "result_dir = '/content/out_frames'\r\n",
        "portrait_in_dir = '/content/U-2-Net/test_data/test_portrait_images/portrait_im'\r\n",
        "portrait_out_dir = '/content/U-2-Net/test_data/test_portrait_images/portrait_results'\r\n",
        "!rm -rf $fg_dir\r\n",
        "!mkdir -p $fg_dir\r\n",
        "!rm -rf $mask_dir\r\n",
        "!mkdir -p $mask_dir\r\n",
        "!rm -rf $bg_dir\r\n",
        "!mkdir -p $bg_dir\r\n",
        "!rm -rf $result_dir\r\n",
        "!mkdir -p $result_dir\r\n",
        "!rm -rf $portrait_in_dir\r\n",
        "!mkdir -p $portrait_in_dir\r\n",
        "!rm -rf $portrait_out_dir\r\n",
        "!mkdir -p $portrait_out_dir\r\n",
        "\r\n",
        "import imageio\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "from time import time\r\n",
        "import io\r\n",
        "import PIL\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from MODNet.src.models.modnet import MODNet\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "\r\n",
        "torch_transforms = transforms.Compose(\r\n",
        "  [\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\r\n",
        "  ]\r\n",
        ")\r\n",
        "\r\n",
        "def fix_dims(im):\r\n",
        "    if im.ndim == 2:\r\n",
        "        im = np.tile(im[..., None], [1, 1, 3])\r\n",
        "    return im[...,:3]\r\n",
        "\r\n",
        "def crop_resize(im, size, crop=False):\r\n",
        "  if im.shape[:2] == size:\r\n",
        "    return im\r\n",
        "  if size[0]<im.shape[0] or size[1]<im.shape[1]:\r\n",
        "    interp = cv2.INTER_AREA\r\n",
        "  else:\r\n",
        "    interp = cv2.INTER_CUBIC\r\n",
        "  if not crop:\r\n",
        "    return np.clip(cv2.resize(im, size[::-1], interpolation=interp),0,1)\r\n",
        "  ratio = max(size[0]/im.shape[0], size[1]/im.shape[1])\r\n",
        "  im = np.clip(cv2.resize(im, (int(np.ceil(im.shape[1]*ratio)), int(np.ceil(im.shape[0]*ratio))), interpolation=interp),0,1)\r\n",
        "  return im[(im.shape[0]-size[0])//2:(im.shape[0]-size[0])//2+size[0], (im.shape[1]-size[1])//2:(im.shape[1]-size[1])//2+size[1]]\r\n",
        "\r\n",
        "ref_size = 512\r\n",
        "def modnet_matting(modnet, im):\r\n",
        "  im_h, im_w = im.shape[:2]\r\n",
        "  im_tensor = torch_transforms(im).float()\r\n",
        "  im_tensor = im_tensor[None, :, :, :].cuda()\r\n",
        "  \r\n",
        "  if max(im_h, im_w) < ref_size or min(im_h, im_w) > ref_size:\r\n",
        "    if im_w >= im_h:\r\n",
        "      im_rh = ref_size\r\n",
        "      im_rw = int(im_w / im_h * ref_size)\r\n",
        "    elif im_w < im_h:\r\n",
        "      im_rw = ref_size\r\n",
        "      im_rh = int(im_h / im_w * ref_size)\r\n",
        "  else:\r\n",
        "    im_rh = im_h\r\n",
        "    im_rw = im_w\r\n",
        "        \r\n",
        "  im_rw = im_rw - im_rw % 32\r\n",
        "  im_rh = im_rh - im_rh % 32\r\n",
        "  \r\n",
        "  if im_h!=im_rh or im_w!=im_rw:\r\n",
        "    im_tensor = F.interpolate(im_tensor, size=(im_rh, im_rw), mode='area')\r\n",
        "  \r\n",
        "  with torch.no_grad():\r\n",
        "    _, _, matte_tensor = modnet(im_tensor, True)\r\n",
        "  matte_tensor = F.interpolate(matte_tensor, size=(im_h, im_w), mode='area')\r\n",
        "  matte_tensor = matte_tensor.repeat(1, 3, 1, 1)\r\n",
        "  return matte_tensor[0].data.cpu().numpy().transpose(1, 2, 0)\r\n",
        "\r\n",
        "grand_start = time()\r\n",
        "start = time()\r\n",
        "try:\r\n",
        "    fg_now = imageio.imread('/content/foreground')\r\n",
        "    fg_now = fix_dims(fg_now)\r\n",
        "    imageio.imwrite(fg_dir+'/frame_%05d.png'%1, fg_now)\r\n",
        "    fg_now = fg_now/255\r\n",
        "except Exception:\r\n",
        "    !ffmpeg $fg_time_params -i /content/foreground $fg_dir/frame_%05d.png\r\n",
        "    fg_now = imageio.imread(fg_dir+'/frame_%05d.png'%1)\r\n",
        "fg_files = [x for x in sorted(os.listdir(fg_dir)) if x.endswith('.png')]\r\n",
        "prepare_time = time()-start\r\n",
        "\r\n",
        "start = time()\r\n",
        "have_u2_mask = False\r\n",
        "if model.startswith('u2net') and (model!='u2net_portrait' or background_url=='foreground' or '://' in background_url or background_url is None):\r\n",
        "  %cd /content/U-2-Net\r\n",
        "  !python /content/U-2-Net/u2net_test.py\r\n",
        "  have_u2_mask = True\r\n",
        "elif model.startswith('modnet'):\r\n",
        "  %cd /content/MODNet\r\n",
        "  modnet = MODNet(backbone_pretrained=False)\r\n",
        "  modnet = nn.DataParallel(modnet).cuda()\r\n",
        "  modnet.load_state_dict(torch.load('/content/MODNet/pretrained/'+model+'_portrait_matting.ckpt'))\r\n",
        "  modnet.eval()\r\n",
        "mask_time = time()-start\r\n",
        "\r\n",
        "blend_time = 0\r\n",
        "is_fg = True\r\n",
        "bg_files = []\r\n",
        "iter_files = fg_files\r\n",
        "rounds = 0\r\n",
        "\r\n",
        "def preproc_bg(bg, fg_now):\r\n",
        "  bg = crop_resize(bg, fg_now.shape[:2], crop=keep_aspect_background)\r\n",
        "  if bokeh_background:\r\n",
        "    if bokeh_gamma>1:\r\n",
        "      bg = bg**bokeh_gamma\r\n",
        "    radius = int(bokeh_prcnt/100*np.sqrt(bg.shape[0]*bg.shape[1])//2*2+1)\r\n",
        "    if radius>1:\r\n",
        "      bg = cv2.GaussianBlur(bg,(radius,radius),0)\r\n",
        "    if bokeh_gamma>1:\r\n",
        "      bg **= 1/bokeh_gamma\r\n",
        "  if gray_background:\r\n",
        "    bg = fix_dims(np.dot(bg, [0.2989, 0.5870, 0.1140]))\r\n",
        "  if mirror_background:\r\n",
        "    bg = np.fliplr(bg)\r\n",
        "  return bg\r\n",
        "\r\n",
        "def mat(in_dir, out_dir, bg_mode, orig_dir=None, fg_mirror=mirror_foreground):\r\n",
        "  global prepare_time, blend_time, fg_now, is_fg, bg_files, iter_files, rounds\r\n",
        "  rounds += 1\r\n",
        "  start = time()\r\n",
        "  if bg_mode == 'white':\r\n",
        "    bg = np.full_like(fg_now, 1)\r\n",
        "  elif bg_mode == 'black':\r\n",
        "    bg = np.full_like(fg_now, 0)\r\n",
        "  elif bg_mode == 'chroma green':\r\n",
        "    bg = np.full_like(fg_now, [0,177/255,64/255])\r\n",
        "  elif bg_mode == 'chroma blue':\r\n",
        "    bg = np.full_like(fg_now, [0,71/255,187/255])\r\n",
        "  elif '://' in background_url or background_url is None:\r\n",
        "    try:\r\n",
        "      bg = imageio.imread('/content/background')/255\r\n",
        "      bg = fix_dims(bg)\r\n",
        "      bg = preproc_bg(bg, fg_now)\r\n",
        "    except Exception:\r\n",
        "      !ffmpeg $bg_time_params -i /content/background $bg_dir/frame_%05d.png\r\n",
        "  elif bg_mode not in ['transparent','foreground']:\r\n",
        "    bg = np.full_like(fg_now, [int(background_url.lstrip('#')[i:i+2], 16)/255 for i in [0, 2, 4]])\r\n",
        "  bg_files = [x for x in sorted(os.listdir(bg_dir)) if x.endswith('.png')]\r\n",
        "  prepare_time += time()-start\r\n",
        "\r\n",
        "  start = time()\r\n",
        "  fg_plus = None\r\n",
        "  mask_plus = None\r\n",
        "  orig = None\r\n",
        "  is_fg = len(fg_files)>1 or not bg_files\r\n",
        "  if is_fg:\r\n",
        "    iter_files = fg_files\r\n",
        "  else:\r\n",
        "    iter_files = bg_files\r\n",
        "    fg_now = imageio.imread(in_dir+'/frame_%05d.png'%1)/255\r\n",
        "    if have_u2_mask:\r\n",
        "      mask = imageio.imread(mask_dir+'/frame_%05d.png'%1)/255\r\n",
        "    elif model.startswith('modnet'):\r\n",
        "      mask = modnet_matting(modnet, fg_now)\r\n",
        "    else:\r\n",
        "      mask = np.ones_like(fg_now)\r\n",
        "    if orig_dir is not None:\r\n",
        "      orig = imageio.imread(orig_dir+'/frame_%05d.png'%1)/255\r\n",
        "    if mirror_foreground:\r\n",
        "      fg_now = np.fliplr(fg_now)\r\n",
        "      mask = np.fliplr(mask)\r\n",
        "      if orig is not None:\r\n",
        "        orig = np.fliplr(orig)\r\n",
        "\r\n",
        "  j = -1\r\n",
        "  j_direction = 1\r\n",
        "  for i,file in enumerate(iter_files):\r\n",
        "      if is_fg:\r\n",
        "        if one_frame_delay and i>0 and i<len(fg_files)-1:\r\n",
        "          fg_now = fg_plus\r\n",
        "          mask_minus = mask_now\r\n",
        "          mask_now = mask_plus\r\n",
        "          if fg_now is None:\r\n",
        "            fg_now = imageio.imread(in_dir+'/'+file)/255\r\n",
        "          if have_u2_mask:\r\n",
        "            if mask_now is None:\r\n",
        "              mask_now = imageio.imread(mask_dir+'/'+file)/255\r\n",
        "            mask_plus = imageio.imread(mask_dir+'/'+fg_files[i+1])/255\r\n",
        "          elif model.startswith('modnet'):\r\n",
        "            if mask_now is None:\r\n",
        "              mask_now = modnet_matting(modnet, fg_now)\r\n",
        "            fg_plus = imageio.imread(in_dir+'/'+fg_files[i+1])/255\r\n",
        "            mask_plus = modnet_matting(modnet, fg_plus)\r\n",
        "          else:\r\n",
        "            if mask_now is None:\r\n",
        "              mask_now = np.ones_like(fg_now)\r\n",
        "            mask_plus = np.ones_like(fg_now)          \r\n",
        "          cond = (np.abs(mask_plus-mask_minus)<=one_frame_delay_threshold) & (np.abs(mask_now-mask_minus)>one_frame_delay_threshold) & (np.abs(mask_now-mask_plus)>one_frame_delay_threshold)\r\n",
        "          mask = mask_now*(1-cond) + (mask_minus+mask_plus)/2*cond\r\n",
        "        else:\r\n",
        "          fg_now = imageio.imread(in_dir+'/'+file)/255\r\n",
        "          if have_u2_mask:\r\n",
        "            mask_now = imageio.imread(mask_dir+'/'+file)/255\r\n",
        "          elif model.startswith('modnet'):\r\n",
        "            mask_now = modnet_matting(modnet, fg_now)\r\n",
        "          else:\r\n",
        "            mask_now = np.ones_like(fg_now)\r\n",
        "          mask = mask_now\r\n",
        "\r\n",
        "        if orig_dir is not None:  \r\n",
        "          orig = imageio.imread(orig_dir+'/'+file)/255\r\n",
        "        if fg_mirror:\r\n",
        "            fg_now = np.fliplr(fg_now)\r\n",
        "            mask = np.fliplr(mask)\r\n",
        "            if orig is not None:\r\n",
        "              orig = np.fliplr(orig)\r\n",
        "        if bg_mode=='foreground':\r\n",
        "          if orig is not None:\r\n",
        "            bg = orig\r\n",
        "          else:\r\n",
        "            bg = fg_now\r\n",
        "        elif bg_files:\r\n",
        "          if loop_reverse_background: \r\n",
        "            j += j_direction\r\n",
        "            if j>=len(bg_files):\r\n",
        "              j = 2*len(bg_files)-j-1\r\n",
        "              j_direction = -1\r\n",
        "            elif j<0:\r\n",
        "              j = 0\r\n",
        "              j_direction = 1\r\n",
        "          else:\r\n",
        "            j = i%len(bg_files)\r\n",
        "          bg = imageio.imread(bg_dir+'/'+bg_files[j])/255\r\n",
        "      \r\n",
        "      else:\r\n",
        "        bg = imageio.imread(bg_dir+'/'+file)/255\r\n",
        "      if bg_files:\r\n",
        "        bg = preproc_bg(bg, fg_now)\r\n",
        "      if bg_mode == 'transparent':\r\n",
        "        im = np.dstack([fg_now,mask[:,:,0]])\r\n",
        "      else:\r\n",
        "        fg = fg_now\r\n",
        "        if orig is not None:\r\n",
        "          if sketch_color=='foreground':\r\n",
        "            fg = 1-(1-fg)*(1-orig)\r\n",
        "          elif 'tint' in sketch_color:\r\n",
        "            non_black_mask = np.any(mask != [0, 0, 0], axis=-1)\r\n",
        "            colors = (orig*mask)[non_black_mask]\r\n",
        "            chroma = np.max(colors, axis=-1)-np.min(colors, axis=-1)\r\n",
        "            chroma_thresholds.sort(reverse=True)\r\n",
        "            if sketch_color=='tint fill':\r\n",
        "              chroma_thresholds.append(0)\r\n",
        "            else:\r\n",
        "              color = np.array([0,0,0])\r\n",
        "            for threshold in chroma_thresholds:\r\n",
        "              cond = chroma>=threshold\r\n",
        "              if np.any(cond):\r\n",
        "                unique, counts = np.unique(colors[cond], axis=0, return_counts=True)\r\n",
        "                color = unique[np.argmax(counts)]\r\n",
        "                break\r\n",
        "            if sketch_color=='tint outline':\r\n",
        "              fg = 1-(1-fg)*(1-color)\r\n",
        "            elif sketch_color=='tint fill':\r\n",
        "              fg = fg*color\r\n",
        "        im = bg*(1-mask)+fg*mask\r\n",
        "      if not is_fg and bg_mode_max_w and fg_now.shape[1]>bg_mode_max_w:\r\n",
        "        h = int(np.round(fg_now.shape[1]/fg_now.shape[0]*w))\r\n",
        "        im = crop_resize(im, (bg_mode_max_w,h), crop=keep_aspect_background)\r\n",
        "      imageio.imwrite(out_dir+'/'+file, np.uint8(im*255), compression=0 if len(fg_files)>1 or bg_files else 9)\r\n",
        "      print('%d/%d (%d)'%(i+1,len(iter_files),rounds))\r\n",
        "  blend_time += time()-start\r\n",
        "\r\n",
        "out_dir = result_dir\r\n",
        "bg_mode = background_url\r\n",
        "if 'u2net_portrait' in model:\r\n",
        "  out_dir = portrait_in_dir\r\n",
        "  bg_mode = 'white' \r\n",
        "if model!='u2net_portrait':\r\n",
        "  mat(fg_dir, out_dir, bg_mode, fg_mirror=False if '+' in model else mirror_foreground)\r\n",
        "elif 'u2net_portrait' in model:\r\n",
        "  !cp $fg_dir/* $portrait_in_dir\r\n",
        "if 'u2net_portrait' in model:\r\n",
        "  %cd /content/U-2-Net\r\n",
        "  start = time()\r\n",
        "  !python /content/U-2-Net/u2net_portrait_test.py\r\n",
        "  blend_time += time()-start\r\n",
        "  if 'foreground' in background_url or '://' in background_url or background_url is None or sketch_color!='gray':\r\n",
        "    mat(portrait_out_dir, result_dir, background_url, orig_dir=fg_dir if 'foreground' in background_url or sketch_color!='gray' else None)\r\n",
        "  else:\r\n",
        "    !mv $portrait_out_dir/* $result_dir\r\n",
        "\r\n",
        "start = time()\r\n",
        "from IPython.display import HTML, clear_output, Image\r\n",
        "from base64 import b64encode\r\n",
        "import shutil\r\n",
        "!rm -f /content/final.mp4\r\n",
        "!rm -f /content/final.png\r\n",
        "if len(fg_files)>1 or bg_files:\r\n",
        "  if is_fg:\r\n",
        "    with imageio.get_reader('/content/foreground', format='mp4') as reader:\r\n",
        "      fps = reader.get_meta_data()['fps']\r\n",
        "    if copy_audio:\r\n",
        "      !ffmpeg -framerate $fps -i $result_dir/frame_%05d.png $fg_time_params -i /content/foreground -c:v libx264 -map 0:v -map 1:a? -vf \"crop=trunc(iw/2)*2:trunc(ih/2)*2\" -pix_fmt yuv420p /content/final.mp4 -y\r\n",
        "    else:\r\n",
        "      !ffmpeg -framerate $fps -i $result_dir/frame_%05d.png -c:v libx264 -vf \"crop=trunc(iw/2)*2:trunc(ih/2)*2\" -pix_fmt yuv420p /content/final.mp4 -y\r\n",
        "  else:\r\n",
        "    with imageio.get_reader('/content/background', format='mp4') as reader:\r\n",
        "      fps = reader.get_meta_data()['fps']\r\n",
        "    if copy_audio:\r\n",
        "      !ffmpeg -framerate $fps -i $result_dir/frame_%05d.png $bg_time_params -i /content/background -c:v libx264 -map 0:v -map 1:a? -vf \"crop=trunc(iw/2)*2:trunc(ih/2)*2\" -pix_fmt yuv420p /content/final.mp4 -y\r\n",
        "    else:\r\n",
        "      !ffmpeg -framerate $fps -i $result_dir/frame_%05d.png -c:v libx264 -vf \"crop=trunc(iw/2)*2:trunc(ih/2)*2\" -pix_fmt yuv420p /content/final.mp4 -y\r\n",
        "  #video can be downloaded from /content/final.mp4\r\n",
        "  save_time = time()-start\r\n",
        "  total_time = time()-grand_start  \r\n",
        "  clear_output()\r\n",
        "  with open('/content/final.mp4', 'rb') as f:\r\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(f.read()).decode()\r\n",
        "  display(HTML(\"\"\"\r\n",
        "  <video width=600 controls autoplay loop>\r\n",
        "        <source src=\"%s\" type=\"video/mp4\">\r\n",
        "  </video>\"\"\" % data_url))\r\n",
        "else:\r\n",
        "  shutil.move(out_dir+'/frame_%05d.png'%1, '/content/final.png')\r\n",
        "  #image can be downloaded from /content/final.png\r\n",
        "  save_time = time()-start\r\n",
        "  total_time = time()-grand_start\r\n",
        "  clear_output()\r\n",
        "  display(Image('/content/final.png', width=600))\r\n",
        "if model.startswith('u2net'):\r\n",
        "    print('frames=%i prepare=%i mask=%i blend=%i save=%i total=%i'%(len(iter_files), prepare_time, mask_time, blend_time, save_time, total_time))\r\n",
        "else:\r\n",
        "    print('frames=%i prepare=%i mask+blend=%i save=%i total=%i'%(len(iter_files), prepare_time, mask_time+blend_time, save_time, total_time))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxy4hscknBvt",
        "cellView": "form"
      },
      "source": [
        "#@title Download\r\n",
        "#@markdown 1. If it fails try running this cell again.\r\n",
        "#@markdown 2. Alternatively, you can manually download \"final.mp4\"/\"final.png\" from the folder on the left (click \"Refresh\" if missing).\r\n",
        "\r\n",
        "print() #see https://github.com/googlecolab/colabtools/issues/468\r\n",
        "from google.colab import files\r\n",
        "if os.path.exists('/content/final.mp4'):\r\n",
        "  files.download('/content/final.mp4') #fails for Firefox private window\r\n",
        "else:\r\n",
        "  files.download('/content/final.png')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}